<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:media="http://www.rssboard.org/media-rss" version="2.0">
<channel>
<title>g-simmons-papercast</title>
<link>https://g-simmons.github.io/g-simmons-papercast/</link>
<language>en-us</language>
<atom:link href="https://g-simmons.github.io/g-simmons-papercast/feed.xml" rel="self" type="application/rss+xml"/>
<copyright>Rights to paper content are reserved by the authors for each paper. I make no claim to ownership or copyright of the content of this podcast.</copyright>
<itunes:subtitle></itunes:subtitle>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:summary>Podcast of text-to-speech for arbitrarily chosen NLP papers.</itunes:summary>
<itunes:keywords>Machine Learning, Natural Language Processing, Artificial Intelligence</itunes:keywords>
<description>Podcast of text-to-speech for arbitrarily chosen NLP papers.</description>
<itunes:owner><itunes:name>Gabriel Simmons</itunes:name><itunes:email>gsimmons@ucdavis.edu</itunes:email></itunes:owner>
<itunes:image href="https://g-simmons.github.io/g-simmons-papercast/cover.jpg"/>
<itunes:category text="Mathematics"></itunes:category>
<itunes:category text="Tech News"></itunes:category>
<itunes:category text="Courses"></itunes:category>


<item>
<title>Structured Prediction as Translation between Augmented Natural Languages</title>
<itunes:title>Structured Prediction as Translation between Augmented Natural Languages</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.]]></itunes:summary>
<description><![CDATA[We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2101.05779v3.Structured_Prediction_as_Translation_between_Augmented_Natural_Languages.mp3" length="" type="audio/mpeg"/>
<itunes:duration>3945.35175</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2101.05779v3.Structured_Prediction_as_Translation_between_Augmented_Natural_Languages.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>Doc2Dict: Information Extraction as Text Generation</title>
<itunes:title>Doc2Dict: Information Extraction as Text Generation</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[]]></itunes:summary>
<description><![CDATA[]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2105.07510v2.Doc2Dict_Information_Extraction_as_Text_Generation.mp3" length="" type="audio/mpeg"/>
<itunes:duration>2235.06275</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2105.07510v2.Doc2Dict_Information_Extraction_as_Text_Generation.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>Zero-Shot Information Extraction as a Unified Text-to-Triple Translation</title>
<itunes:title>Zero-Shot Information Extraction as a Unified Text-to-Triple Translation</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[We cast a suite of information extraction tasks into a text-to-triple translation framework. Instead of solving each task relying on task-specific datasets and models, we formalize the task as a translation between task-specific input text and output triples. By taking the task-specific input, we enable a task-agnostic translation by leveraging the latent knowledge that a pre-trained language model has about the task. We further demonstrate that a simple pre-training task of predicting which relational information corresponds to which input text is an effective way to produce task-specific outputs. This enables the zero-shot transfer of our framework to downstream tasks. We study the zero-shot performance of this framework on open information extraction (OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and factual probe (Google-RE and T-REx). The model transfers non-trivially to most tasks and is often competitive with a fully supervised method without the need for any task-specific training. For instance, we significantly outperform the F1 score of the supervised open information extraction without needing to use its training set.]]></itunes:summary>
<description><![CDATA[We cast a suite of information extraction tasks into a text-to-triple translation framework. Instead of solving each task relying on task-specific datasets and models, we formalize the task as a translation between task-specific input text and output triples. By taking the task-specific input, we enable a task-agnostic translation by leveraging the latent knowledge that a pre-trained language model has about the task. We further demonstrate that a simple pre-training task of predicting which relational information corresponds to which input text is an effective way to produce task-specific outputs. This enables the zero-shot transfer of our framework to downstream tasks. We study the zero-shot performance of this framework on open information extraction (OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and factual probe (Google-RE and T-REx). The model transfers non-trivially to most tasks and is often competitive with a fully supervised method without the need for any task-specific training. For instance, we significantly outperform the F1 score of the supervised open information extraction without needing to use its training set.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2109.11171v1.Zero_Shot_Information_Extraction_as_a_Unified_Text_to_Triple_Translation.mp3" length="" type="audio/mpeg"/>
<itunes:duration>2476.565</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2109.11171v1.Zero_Shot_Information_Extraction_as_a_Unified_Text_to_Triple_Translation.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>


</channel>
</rss>