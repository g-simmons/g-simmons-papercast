<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:media="http://www.rssboard.org/media-rss" version="2.0">
<channel>
<title>g-simmons-papercast</title>
<link>https://g-simmons.github.io/g-simmons-papercast/</link>
<language>en-us</language>
<atom:link href="https://g-simmons.github.io/g-simmons-papercast/feed.xml" rel="self" type="application/rss+xml"/>
<copyright>Rights to paper content are reserved by the authors for each paper. I make no claim to ownership or copyright of the content of this podcast.</copyright>
<itunes:subtitle></itunes:subtitle>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:summary>Podcast of text-to-speech for arbitrarily chosen NLP papers.</itunes:summary>
<itunes:keywords>Machine Learning, Natural Language Processing, Artificial Intelligence</itunes:keywords>
<description>Podcast of text-to-speech for arbitrarily chosen NLP papers.</description>
<itunes:owner><itunes:name>Gabriel Simmons</itunes:name><itunes:email>gsimmons@ucdavis.edu</itunes:email></itunes:owner>
<itunes:image href="https://g-simmons.github.io/g-simmons-papercast/cover.jpg"/>
<itunes:category text="Mathematics"></itunes:category>
<itunes:category text="Tech News"></itunes:category>
<itunes:category text="Courses"></itunes:category>


<item>
<title>Structured Prediction as Translation between Augmented Natural Languages</title>
<itunes:title>Structured Prediction as Translation between Augmented Natural Languages</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.]]></itunes:summary>
<description><![CDATA[We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2101.05779v3.Structured_Prediction_as_Translation_between_Augmented_Natural_Languages.mp3" length="" type="audio/mpeg"/>
<itunes:duration>3945.35175</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2101.05779v3.Structured_Prediction_as_Translation_between_Augmented_Natural_Languages.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>Doc2Dict: Information Extraction as Text Generation</title>
<itunes:title>Doc2Dict: Information Extraction as Text Generation</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[]]></itunes:summary>
<description><![CDATA[]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2105.07510v2.Doc2Dict_Information_Extraction_as_Text_Generation.mp3" length="" type="audio/mpeg"/>
<itunes:duration>2235.06275</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2105.07510v2.Doc2Dict_Information_Extraction_as_Text_Generation.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge
  Base Population</title>
<itunes:title>DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge
  Base Population</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[We present a new open-source and extensible knowledge extraction toolkit, called DeepKE (Deep learning based Knowledge Extraction), supporting standard fully supervised, low-resource few-shot and document-level scenarios. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured texts according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. Besides, we present an online platform in http://deepke.zjukg.cn/ for real-time extraction of various tasks. DeepKE has been equipped with Google Colab tutorials and comprehensive documents for beginners. We release the source code at https://github.com/zjunlp/DeepKE, with a demo video.]]></itunes:summary>
<description><![CDATA[We present a new open-source and extensible knowledge extraction toolkit, called DeepKE (Deep learning based Knowledge Extraction), supporting standard fully supervised, low-resource few-shot and document-level scenarios. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured texts according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. Besides, we present an online platform in http://deepke.zjukg.cn/ for real-time extraction of various tasks. DeepKE has been equipped with Google Colab tutorials and comprehensive documents for beginners. We release the source code at https://github.com/zjunlp/DeepKE, with a demo video.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2201.03335v2.DeepKE_A_Deep_Learning_Based_Knowledge_Extraction_Toolkit_for_Knowledge_Base_Population.mp3" length="" type="audio/mpeg"/>
<itunes:duration>1716.8195</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2201.03335v2.DeepKE_A_Deep_Learning_Based_Knowledge_Extraction_Toolkit_for_Knowledge_Base_Population.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>A Fully Differentiable Beam Search Decoder</title>
<itunes:title>A Fully Differentiable Beam Search Decoder</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[We introduce a new beam search decoder that is fully differentiable, making it possible to optimize at training time through the inference procedure. Our decoder allows us to combine models which operate at different granularities (e.g. acoustic and language models). It can be used when target sequences are not aligned to input sequences by considering all possible alignments between the two. We demonstrate our approach scales by applying it to speech recognition, jointly training acoustic and word-level language models. The system is end-to-end, with gradients flowing through the whole architecture from the word-level transcriptions. Recent research efforts have shown that deep neural networks with attention-based mechanisms are powerful enough to successfully train an acoustic model from the final transcription, while implicitly learning a language model. Instead, we show that it is possible to discriminatively train an acoustic model jointly with an explicit and possibly pre-trained language model.]]></itunes:summary>
<description><![CDATA[We introduce a new beam search decoder that is fully differentiable, making it possible to optimize at training time through the inference procedure. Our decoder allows us to combine models which operate at different granularities (e.g. acoustic and language models). It can be used when target sequences are not aligned to input sequences by considering all possible alignments between the two. We demonstrate our approach scales by applying it to speech recognition, jointly training acoustic and word-level language models. The system is end-to-end, with gradients flowing through the whole architecture from the word-level transcriptions. Recent research efforts have shown that deep neural networks with attention-based mechanisms are powerful enough to successfully train an acoustic model from the final transcription, while implicitly learning a language model. Instead, we show that it is possible to discriminatively train an acoustic model jointly with an explicit and possibly pre-trained language model.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/1902.06022v1.A_Fully_Differentiable_Beam_Search_Decoder.mp3" length="" type="audio/mpeg"/>
<itunes:duration>2335.11175</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/1902.06022v1.A_Fully_Differentiable_Beam_Search_Decoder.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>Zero-Shot Information Extraction as a Unified Text-to-Triple Translation</title>
<itunes:title>Zero-Shot Information Extraction as a Unified Text-to-Triple Translation</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[We cast a suite of information extraction tasks into a text-to-triple translation framework. Instead of solving each task relying on task-specific datasets and models, we formalize the task as a translation between task-specific input text and output triples. By taking the task-specific input, we enable a task-agnostic translation by leveraging the latent knowledge that a pre-trained language model has about the task. We further demonstrate that a simple pre-training task of predicting which relational information corresponds to which input text is an effective way to produce task-specific outputs. This enables the zero-shot transfer of our framework to downstream tasks. We study the zero-shot performance of this framework on open information extraction (OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and factual probe (Google-RE and T-REx). The model transfers non-trivially to most tasks and is often competitive with a fully supervised method without the need for any task-specific training. For instance, we significantly outperform the F1 score of the supervised open information extraction without needing to use its training set.]]></itunes:summary>
<description><![CDATA[We cast a suite of information extraction tasks into a text-to-triple translation framework. Instead of solving each task relying on task-specific datasets and models, we formalize the task as a translation between task-specific input text and output triples. By taking the task-specific input, we enable a task-agnostic translation by leveraging the latent knowledge that a pre-trained language model has about the task. We further demonstrate that a simple pre-training task of predicting which relational information corresponds to which input text is an effective way to produce task-specific outputs. This enables the zero-shot transfer of our framework to downstream tasks. We study the zero-shot performance of this framework on open information extraction (OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and factual probe (Google-RE and T-REx). The model transfers non-trivially to most tasks and is often competitive with a fully supervised method without the need for any task-specific training. For instance, we significantly outperform the F1 score of the supervised open information extraction without needing to use its training set.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2109.11171v1.Zero_Shot_Information_Extraction_as_a_Unified_Text_to_Triple_Translation.mp3" length="" type="audio/mpeg"/>
<itunes:duration>2476.565</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2109.11171v1.Zero_Shot_Information_Extraction_as_a_Unified_Text_to_Triple_Translation.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>

<item>
<title>KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization
  for Relation Extraction</title>
<itunes:title>KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization
  for Relation Extraction</itunes:title>
<itunes:author>Gabriel Simmons</itunes:author>
<itunes:subtitle></itunes:subtitle>
<itunes:summary><![CDATA[Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and time-consuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in https://github.com/zjunlp/KnowPrompt for reproducibility.]]></itunes:summary>
<description><![CDATA[Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and time-consuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in https://github.com/zjunlp/KnowPrompt for reproducibility.]]></description>
<enclosure url="https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2104.07650v6.KnowPrompt_Knowledge_aware_Prompt_tuning_with_Synergistic_Optimization_for_Relation_Extraction.mp3" length="" type="audio/mpeg"/>
<itunes:duration>2580.454</itunes:duration>
<itunes:season>1</itunes:season>
<itunes:episode></itunes:episode>
<itunes:episodeType>full</itunes:episodeType>
<guid isPermaLink="false">https://g-simmons.github.io/g-simmons-papercast/data/mp3s/2104.07650v6.KnowPrompt_Knowledge_aware_Prompt_tuning_with_Synergistic_Optimization_for_Relation_Extraction.mp3</guid>
<pubDate></pubDate>
<itunes:explicit>NO</itunes:explicit>
</item>


</channel>
</rss>